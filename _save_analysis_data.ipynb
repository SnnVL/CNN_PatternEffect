{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da79c16-eb43-4664-a883-7a31f3af00da",
   "metadata": {
    "id": "4a650402-4774-49cb-9b72-9c8f1dd02f1d",
    "tags": []
   },
   "source": [
    "# Save results for predicting Radiation from SSTs and its ingredients\n",
    "authors: Maria Rugenstein, Elizabeth A. Barnes, and Senne Van Loon\n",
    "\n",
    "date: March 7, 2024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ccff821-b304-4009-8fe8-75a213b3f421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb968382-4186-466e-a85b-b00caa5fc9be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17642,
     "status": "ok",
     "timestamp": 1646449680995,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "fb968382-4186-466e-a85b-b00caa5fc9be",
    "outputId": "d7964af9-2d52-4466-902d-9b85faba9a91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import gc\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import experiment_settings, xai\n",
    "import file_methods, plots, data_processing\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "import cartopy as ct\n",
    "from cartopy.util import add_cyclic_point\n",
    "from cmcrameri import cm\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "mpl.rcParams[\"savefig.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"figure.dpi\"] = 150\n",
    "savefig_dpi = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5cee3-6f4f-4818-92e1-1351eeeb565a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1646449681009,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "29a5cee3-6f4f-4818-92e1-1351eeeb565a",
    "outputId": "e5f5b0ac-82b8-4147-bf44-4bc3b49466a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DIRECTORIES import MODEL_DIRECTORY, PREDICTIONS_DIRECTORY, NETCDF_DIRECTORY, DATA_DIRECTORY\n",
    "\n",
    "SAVE_NETCDF = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "651315ce-eecc-4d30-8b90-c97d08936315",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a544f-ef35-417f-bec4-62225d885014",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP_model = \"MPI\"\n",
    "# base_exp = \"_IV\"\n",
    "base_exp = \"_hist_rcp85\"\n",
    "suffix = \"\"\n",
    "\n",
    "savename_prefix = \"R_\"+CMIP_model+base_exp+suffix\n",
    "experiment_dict = {\n",
    "    \"InternalVariability\": CMIP_model+\"_IV\"+suffix,\n",
    "    \"InternalVariability_linear\": CMIP_model+\"_IV_linear\",\n",
    "}\n",
    "if CMIP_model == \"MPI\":\n",
    "    experiment_dict[\"greens_function\"]= \"MPI_GF\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c807abd7-832a-484b-98cd-7e6c3a9f60c0",
   "metadata": {
    "id": "c807abd7-832a-484b-98cd-7e6c3a9f60c0",
    "tags": []
   },
   "source": [
    "## Load the data and saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806b597",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BASE DATA\n",
    "settings_base = experiment_settings.get_settings(CMIP_model+base_exp)\n",
    "\n",
    "# Set seeds\n",
    "rng_seed = settings_base[\"rng_seed_list\"][0]\n",
    "settings_base[\"rng_seed\"] = rng_seed\n",
    "tf.random.set_seed(settings_base[\"rng_seed\"])\n",
    "random.seed(settings_base[\"rng_seed\"])\n",
    "np.random.seed(settings_base[\"rng_seed\"])\n",
    "\n",
    "# GET THE DATA\n",
    "(\n",
    "    _,\n",
    "    _,\n",
    "    x_test,\n",
    "    _,\n",
    "    _,\n",
    "    labels_test,\n",
    "    lat,\n",
    "    lon,\n",
    "    map_shape,\n",
    "    member_shape,\n",
    "    time_shape,\n",
    "    _,\n",
    "    member_enrollment,\n",
    "    _,\n",
    ") = data_processing.get_cmip_data(\n",
    "    DATA_DIRECTORY,\n",
    "    settings_base,\n",
    "    n_train_val_test=settings_base[\"n_train_val_test\"],\n",
    ")\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "sims_dict = {}\n",
    "for exp_type in experiment_dict.keys():\n",
    "    print(\"*********  \"+exp_type+\"  *********\")\n",
    "\n",
    "    # Get model settings\n",
    "    settings = experiment_settings.get_settings(experiment_dict[exp_type])\n",
    "\n",
    "    # Load model\n",
    "    settings[\"rng_seed\"] = rng_seed\n",
    "    model_name = file_methods.get_model_name(settings)\n",
    "    if not os.path.exists(MODEL_DIRECTORY + model_name + \"_model\"):\n",
    "        raise RuntimeError(\"No such model experiment: \" + model_name)\n",
    "    model = file_methods.load_tf_model(model_name, MODEL_DIRECTORY)\n",
    "\n",
    "    # Load predictions\n",
    "    predictions = file_methods.load_predictions(PREDICTIONS_DIRECTORY + model_name + \"_predictions.pickle\")\n",
    "\n",
    "    # Make OOS predictions\n",
    "    predictions[\"labels_oos_test\"] = labels_test\n",
    "    predictions[\"pred_oos_test\"] = model.predict(x_test)\n",
    "\n",
    "    # Metrics (Validation, testing, OOS)\n",
    "    mse = metrics.mean_squared_error(\n",
    "            predictions[\"labels_val\"], predictions[\"pred_val\"]\n",
    "        )\n",
    "    r2 = metrics.r2_score(\n",
    "                predictions[\"labels_val\"], predictions[\"pred_val\"]\n",
    "            )\n",
    "    print(\"Validation:  \"\\\n",
    "         +\"mse = \"+plots.num_lab(mse,4)\\\n",
    "         +\", r2 = \"+plots.num_lab(r2,4))\n",
    "    \n",
    "    mse = metrics.mean_squared_error(\n",
    "            predictions[\"labels_test\"], predictions[\"pred_test\"]\n",
    "        )\n",
    "    r2 = metrics.r2_score(\n",
    "                predictions[\"labels_test\"], predictions[\"pred_test\"]\n",
    "            )\n",
    "    print(\"Testing:     \"\\\n",
    "         +\"mse = \"+plots.num_lab(mse,4)\\\n",
    "         +\", r2 = \"+plots.num_lab(r2,4))\n",
    "    \n",
    "    mse = metrics.mean_squared_error(\n",
    "            predictions[\"labels_oos_test\"], predictions[\"pred_oos_test\"]\n",
    "        )\n",
    "    r2 = metrics.r2_score(\n",
    "                predictions[\"labels_oos_test\"], predictions[\"pred_oos_test\"]\n",
    "            )\n",
    "    print(\"Testing OOS: \"\\\n",
    "         +\"mse = \"+plots.num_lab(mse,4)\\\n",
    "         +\", r2 = \"+plots.num_lab(r2,4))\n",
    "    print(\"\")\n",
    "\n",
    "    # Save settings + predictions\n",
    "    sims_dict[exp_type] = {\n",
    "        \"model\": model,\n",
    "        \"predictions\": predictions,\n",
    "        \"settings\": settings,\n",
    "        \"type\": exp_type,\n",
    "    }\n",
    "\n",
    "    # clear things out\n",
    "    __ = gc.collect()\n",
    "\n",
    "print(sims_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = NETCDF_DIRECTORY + savename_prefix + \"_predictions_test.nc\"\n",
    "\n",
    "# Define years\n",
    "years = np.arange(settings_base[\"yr_bounds\"][0], settings_base[\"yr_bounds\"][1] + 1)\n",
    "\n",
    "# Save labels\n",
    "data_vars_dict = {}\n",
    "data_vars_dict = dict(\n",
    "    labels=(\n",
    "        [\"member\", \"year\"],\n",
    "        labels_test.reshape(\n",
    "            settings_base[\"n_train_val_test\"][2], time_shape\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Save OOS predictions\n",
    "for exp_type in sims_dict.keys():\n",
    "    data_vars_dict[exp_type] = (\n",
    "        [\"member\", \"year\"],\n",
    "        sims_dict[exp_type][\"predictions\"][\"pred_oos_test\"].reshape(\n",
    "            sims_dict[exp_type][\"settings\"][\"n_train_val_test\"][2], time_shape\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Make Dataset\n",
    "ds = xr.Dataset(\n",
    "    data_vars=data_vars_dict,\n",
    "    coords=dict(\n",
    "        year=years,\n",
    "        member=member_enrollment[2],\n",
    "    ),\n",
    "    attrs=dict(description=\"Data from experiments: \" + str(list(experiment_dict.values()))),\n",
    ")\n",
    "\n",
    "# Save to file\n",
    "if SAVE_NETCDF:\n",
    "    ds.to_netcdf(filename, format=\"NETCDF4\")\n",
    "display(ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7), dpi=250)\n",
    "plt.plot(ds[\"year\"], ds[\"labels\"][0, :], label=\"labels\", linestyle=\"-\", linewidth=10, alpha=0.5, color=\"gray\")\n",
    "\n",
    "for varname, da in ds.data_vars.items():\n",
    "    if varname == \"labels\":\n",
    "        continue\n",
    "    if \"nonlinear\" in varname:\n",
    "        lt, alpha = \"-\", 0.75\n",
    "    else:\n",
    "        lt, alpha = \"--\", 1.0\n",
    "    plt.plot(ds[\"year\"], da[0, :], label=varname, linestyle=lt, alpha=alpha, linewidth=2.5)\n",
    "\n",
    "plt.title(\"member #0\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9112b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_exp[:5] == '_1pct' or base_exp == \"_IV\":\n",
    "    raise ValueError()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## COMPUTE GRADIENTS\n",
    "Gradients are computed on in-sample testing members, and averaged over all members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefilename = NETCDF_DIRECTORY + \"R_\" + CMIP_model + suffix + \"_xaiGrads_test.nc\"\n",
    "\n",
    "# Define years and evaluating data\n",
    "years = np.arange(settings[\"yr_bounds\"][0], settings[\"yr_bounds\"][1] + 1)\n",
    "\n",
    "data_vars_dict = {}\n",
    "for exp_type in sims_dict.keys():\n",
    "    # Get in-sample test data\n",
    "    (_,_,x_eval,_,_,_,_,_,_,_,_,_,_,_,) = data_processing.get_cmip_data(\n",
    "        DATA_DIRECTORY,\n",
    "        sims_dict[exp_type][\"settings\"],\n",
    "        n_train_val_test=sims_dict[exp_type][\"settings\"][\"n_train_val_test\"],\n",
    "    )\n",
    "    x_eval = x_eval.astype('float32')\n",
    "\n",
    "    # Reshape x_eval (otherwise leads to memory issues)\n",
    "    x_eval = x_eval.reshape((sims_dict[exp_type][\"settings\"][\"n_train_val_test\"][2], time_shape, map_shape[0], map_shape[1],1))\n",
    "\n",
    "    # Initialize gradients\n",
    "    grads = np.empty((sims_dict[exp_type][\"settings\"][\"n_train_val_test\"][2], time_shape, map_shape[0], map_shape[1]))\n",
    "\n",
    "    # Compute gradients\n",
    "    for mm in range(sims_dict[exp_type][\"settings\"][\"n_train_val_test\"][2]):\n",
    "        grads[mm,:,:,:] = xai.get_gradients(sims_dict[exp_type][\"model\"], \\\n",
    "                                             x_eval[mm,:,:,:,:], pred_idx=0)\n",
    "\n",
    "    # Apply mask to gradient\n",
    "    mask = xr.load_dataarray(DATA_DIRECTORY + settings[\"input_region\"]).to_numpy()\n",
    "    grads = grads * mask\n",
    "    grads = grads.astype('float32')\n",
    "    \n",
    "    # Take ensemble mean\n",
    "    grads = grads.mean(axis=0)\n",
    "    grads[grads == 0] = np.nan\n",
    "    data_vars_dict[exp_type] = ([\"year\", \"lat\", \"lon\"], grads.copy())\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Create dataset\n",
    "ds = xr.Dataset(\n",
    "    data_vars=data_vars_dict,\n",
    "    coords=dict(\n",
    "        year=years,\n",
    "        lat=lat.astype('float32'),\n",
    "        lon=lon.astype('float32'),\n",
    "    ),\n",
    "    attrs=dict(description=\"Data from experiments: \" + str(list(experiment_dict.values()))),\n",
    ")\n",
    "if SAVE_NETCDF:\n",
    "    ds.to_netcdf(savefilename, format=\"NETCDF4\")\n",
    "display(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.linspace(-0.0013,0.0013,27)\n",
    "t = np.linspace(-0.001 ,0.001 ,3)\n",
    "norm = mpl.colors.BoundaryNorm(l, cm.vik.N)\n",
    "\n",
    "for varname, da in ds.data_vars.items():\n",
    "\n",
    "    x_plot, lons_cyc = add_cyclic_point(da.to_numpy().mean(axis=0), coord=lon)\n",
    "\n",
    "    # Setup figure\n",
    "    fig, ax = plots.setup_figure(nCols=1,nRows=1,size=(5,4),mask=True)\n",
    "\n",
    "    cf = ax.pcolormesh(lons_cyc,lat,x_plot\\\n",
    "                      ,norm=norm\\\n",
    "                      ,transform=plots.data_crs\\\n",
    "                      ,cmap=cm.vik)\n",
    "    cb = plt.colorbar(cf,ax=ax, orientation = \"horizontal\",shrink=1.0, extend='both',ticks=t)\n",
    "    cb.set_label(\"Gradient [W/m$^2$/K]\")\n",
    "    ax.set_title(varname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd3d4742",
   "metadata": {},
   "source": [
    "## COMPUTE ATTRIBUTION\n",
    "Gradients are computed on in-sample testing members, multiplied by out-of-sample SST, and averaged over all members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ac498",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefilename = NETCDF_DIRECTORY + savename_prefix + \"_xaiAttribution_test.nc\"\n",
    "\n",
    "# Define years and evaluating data\n",
    "years = np.arange(settings[\"yr_bounds\"][0], settings[\"yr_bounds\"][1] + 1)\n",
    "\n",
    "x_test_ = x_test.reshape((settings_base[\"n_train_val_test\"][2], time_shape, map_shape[0], map_shape[1],1))\n",
    "\n",
    "data_vars_dict = {}\n",
    "for exp_type in sims_dict.keys():\n",
    "\n",
    "    # Initialize gradients\n",
    "    grads = np.empty((sims_dict[exp_type][\"settings\"][\"n_train_val_test\"][2], time_shape, map_shape[0], map_shape[1]))\n",
    "\n",
    "    # Compute gradients * SST\n",
    "    for mm in range(sims_dict[exp_type][\"settings\"][\"n_train_val_test\"][2]):\n",
    "        grads[mm,:,:,:] = xai.get_gradients(sims_dict[exp_type][\"model\"], \\\n",
    "                            x_test_[mm,:,:,:,:], pred_idx=0) \\\n",
    "                          * np.squeeze(x_test_)[mm,:,:,:]\n",
    "\n",
    "    # Apply mask\n",
    "    mask = xr.load_dataarray(DATA_DIRECTORY + settings[\"input_region\"]).to_numpy()\n",
    "    grads = grads * mask\n",
    "    grads = grads.astype('float32')\n",
    "\n",
    "    # Take ensemble mean\n",
    "    grads = grads.mean(axis=0)\n",
    "    grads[grads == 0] = np.nan\n",
    "    data_vars_dict[exp_type] = ([\"year\", \"lat\", \"lon\"], grads.copy())\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Create dataset\n",
    "ds = xr.Dataset(\n",
    "    data_vars=data_vars_dict,\n",
    "    coords=dict(\n",
    "        year=years,\n",
    "        lat=lat,\n",
    "        lon=lon,\n",
    "    ),\n",
    "    attrs=dict(description=\"Data from experiments: \" + str(list(experiment_dict.values()))),\n",
    ")\n",
    "if SAVE_NETCDF:\n",
    "    ds.to_netcdf(savefilename, format=\"NETCDF4\")\n",
    "display(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb809034",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.linspace(-0.002,0.002,21)\n",
    "t = np.linspace(-0.002,0.002,5)\n",
    "norm = mpl.colors.BoundaryNorm(l, cm.vik.N)\n",
    "\n",
    "for varname, da in ds.data_vars.items():\n",
    "\n",
    "    x_plot, lons_cyc = add_cyclic_point(da.to_numpy().mean(axis=0), coord=lon)\n",
    "\n",
    "    # Setup figure\n",
    "    fig, ax = plots.setup_figure(nCols=1,nRows=1,size=(5,4),mask=True)\n",
    "\n",
    "    cf = ax.pcolormesh(lons_cyc,lat,x_plot\\\n",
    "                      ,norm=norm\\\n",
    "                      ,transform=plots.data_crs\\\n",
    "                      ,cmap=cm.vik)\n",
    "    cb = plt.colorbar(cf,ax=ax, orientation = \"horizontal\",shrink=1.0, extend='both',ticks=t)\n",
    "    cb.set_label(\"Attribution [W/m$^2$]\")\n",
    "    ax.set_title(varname)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 6))\n",
    "for varname, da in ds.data_vars.items():\n",
    "    ax.plot(da['year'],np.nansum(da.to_numpy(),axis=(1,2)),label=varname)\n",
    "ax.set_xlabel(\"year\")\n",
    "ax.set_ylabel(\"Radiation [W/m$^2$]\")\n",
    "ax.set_xlim(da['year'][0],da['year'][-1])\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "_main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env-tfp-2.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3f78fa1a6f86502de405b2eccf3980e4162dd8f30b677c88688b0edf6ffae37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
