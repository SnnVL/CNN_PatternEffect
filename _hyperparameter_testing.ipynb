{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib as imp\n",
    "import importlib as imp\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import experiment_settings\n",
    "import file_methods, plots, data_processing\n",
    "from DIRECTORIES import PREDICTIONS_DIRECTORY\n",
    "\n",
    "savefig_dpi = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles(label,preds,th=5):\n",
    "    p5, p95 = np.percentile(label,(th,100-th))\n",
    "    \n",
    "    idx5  = (label<=p5 )\n",
    "    idx95 = (label>=p95)\n",
    "\n",
    "    return label[idx5], preds[idx5], label[idx95], preds[idx95]\n",
    "\n",
    "def mean_error(labels,preds):\n",
    "    return np.mean(labels-preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"MPI_IV_hpt00\"\n",
    "percentile_th = 5\n",
    "\n",
    "imp.reload(data_processing)\n",
    "imp.reload(experiment_settings)\n",
    "imp.reload(file_methods)\n",
    "\n",
    "NUM_HPT = 9\n",
    "MSE = np.empty((NUM_HPT,5))\n",
    "MAE = np.empty((NUM_HPT,5))\n",
    "MXE  = np.empty((NUM_HPT,5))\n",
    "ME  = np.empty((NUM_HPT,5))\n",
    "R2  = np.empty((NUM_HPT,5))\n",
    "\n",
    "MSE_5 = np.empty((NUM_HPT,5))\n",
    "MAE_5 = np.empty((NUM_HPT,5))\n",
    "MXE_5  = np.empty((NUM_HPT,5))\n",
    "ME_5  = np.empty((NUM_HPT,5))\n",
    "R2_5  = np.empty((NUM_HPT,5))\n",
    "\n",
    "MSE_95 = np.empty((NUM_HPT,5))\n",
    "MAE_95 = np.empty((NUM_HPT,5))\n",
    "MXE_95  = np.empty((NUM_HPT,5))\n",
    "ME_95  = np.empty((NUM_HPT,5))\n",
    "R2_95  = np.empty((NUM_HPT,5))\n",
    "\n",
    "for hpt in range(NUM_HPT):\n",
    "    print(\"*********  \"+EXP_NAME+str(hpt)+\"  *********\")\n",
    "\n",
    "    # Get model settings\n",
    "    settings = experiment_settings.get_settings(EXP_NAME+str(hpt))\n",
    "\n",
    "    # Load predictions\n",
    "    for rng_seed in settings[\"rng_seed_list\"]:\n",
    "        settings[\"rng_seed\"] = rng_seed\n",
    "        model_name = file_methods.get_model_name(settings)\n",
    "        predictions = file_methods.load_predictions(PREDICTIONS_DIRECTORY + model_name + \"_predictions.pickle\")\n",
    "\n",
    "        label5, preds5, label95, preds95 = get_percentiles(predictions[\"labels_val\"], predictions[\"pred_val\"], th=percentile_th)\n",
    "\n",
    "        # Metrics (Validation, testing, OOS)\n",
    "        MSE[hpt,rng_seed] = metrics.mean_squared_error(\n",
    "                predictions[\"labels_val\"], predictions[\"pred_val\"]\n",
    "            )\n",
    "        MAE[hpt,rng_seed] = metrics.mean_absolute_error(\n",
    "                predictions[\"labels_val\"], predictions[\"pred_val\"]\n",
    "            )\n",
    "        MXE[hpt,rng_seed] = metrics.max_error(\n",
    "                predictions[\"labels_val\"], predictions[\"pred_val\"]\n",
    "            )\n",
    "        ME[hpt,rng_seed] = mean_error(\n",
    "                predictions[\"labels_val\"], predictions[\"pred_val\"]\n",
    "            )\n",
    "        R2[hpt,rng_seed] = metrics.r2_score(\n",
    "                predictions[\"labels_val\"], predictions[\"pred_val\"]\n",
    "            )\n",
    "        \n",
    "        MSE_5[hpt,rng_seed] = metrics.mean_squared_error(\n",
    "                label5, preds5\n",
    "            )\n",
    "        MAE_5[hpt,rng_seed] = metrics.mean_absolute_error(\n",
    "                label5, preds5\n",
    "            )\n",
    "        MXE_5[hpt,rng_seed] = metrics.max_error(\n",
    "                label5, preds5\n",
    "            )\n",
    "        ME_5[hpt,rng_seed] = mean_error(\n",
    "                label5, preds5\n",
    "            )\n",
    "        R2_5[hpt,rng_seed] = metrics.r2_score(\n",
    "                label5, preds5\n",
    "            )\n",
    "        \n",
    "        MSE_95[hpt,rng_seed] = metrics.mean_squared_error(\n",
    "                label95, preds95\n",
    "            )\n",
    "        MAE_95[hpt,rng_seed] = metrics.mean_absolute_error(\n",
    "                label95, preds95\n",
    "            )\n",
    "        MXE_95[hpt,rng_seed] = metrics.max_error(\n",
    "                label95, preds95\n",
    "            )\n",
    "        ME_95[hpt,rng_seed] = mean_error(\n",
    "                label95, preds95\n",
    "            )\n",
    "        R2_95[hpt,rng_seed] = metrics.r2_score(\n",
    "                label95, preds95\n",
    "            )\n",
    "        print(\"Seed \"+str(rng_seed)+\":  \"\\\n",
    "            +\"mse = \"+plots.num_lab(MSE[hpt,rng_seed],3)\\\n",
    "            +\", mae = \"+plots.num_lab(MAE[hpt,rng_seed],3)\\\n",
    "            +\", me = \"+plots.num_lab(MXE[hpt,rng_seed],3)\\\n",
    "            +\", r2 = \"+plots.num_lab(R2[hpt,rng_seed],3)\\\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = [\"hpt\"+str(ii) for ii in range(1,NUM_HPT+1)]\n",
    "\n",
    "RMSE = np.sqrt(MSE)\n",
    "RMSE_5 = np.sqrt(MSE_5)\n",
    "RMSE_95 = np.sqrt(MSE_95)\n",
    "\n",
    "exp_num = np.arange(NUM_HPT)\n",
    "PLOT = np.empty(5,dtype='object')\n",
    "\n",
    "fig, axs = plt.subplots(2,3,figsize=(20, 13))\n",
    "for qt in range(3):\n",
    "    if qt==0:\n",
    "        PLOT = np.array([RMSE, MAE, R2, MXE, ME])\n",
    "        shift = 0.0\n",
    "        clr = 'k'\n",
    "    elif qt==1:\n",
    "        PLOT = np.array([RMSE_5, MAE_5, R2_5, MXE_5, ME_5])\n",
    "        shift = 0.15\n",
    "        clr = 'r'\n",
    "    elif qt==2:\n",
    "        PLOT = np.array([RMSE_95, MAE_95, R2_95, MXE_95, ME_95])\n",
    "        shift =-0.15\n",
    "        clr = 'g'\n",
    "\n",
    "\n",
    "    for jj in range(5):\n",
    "        ax = plt.subplot(2, 3, jj+1)\n",
    "        for ii in range(5):\n",
    "            ax.scatter(exp_num+shift,PLOT[jj,:,ii],color=clr,s=15)\n",
    "        ax.scatter(3+shift,PLOT[jj,3,3],marker='*',color=clr,s=100)\n",
    "\n",
    "        for val in exp_num:\n",
    "            ax.plot([val+0.5,val+0.5],[-10,10],color='gray',alpha=0.1)\n",
    "\n",
    "        if qt==0:\n",
    "            ax.set_xlim(-0.5,val+0.5)\n",
    "            ax.set_xticks(range(NUM_HPT))\n",
    "            ax.set_xticklabels(lbls, rotation=45,fontsize=14)\n",
    "            if jj == 0:\n",
    "                ax.set_ylabel(\"Root mean squared error [W/m$^2$]\",fontsize=14)\n",
    "                ax.set_ylim(0.1,0.24)\n",
    "                ax.set_title(\"(a)\",fontsize=15)\n",
    "            elif jj == 1:\n",
    "                ax.set_ylabel(\"Mean absolute error [W/m$^2$]\",fontsize=14)\n",
    "                ax.set_ylim(0.1,0.24)\n",
    "                ax.set_title(\"(b)\",fontsize=15)\n",
    "            elif jj == 2:\n",
    "                ax.set_ylabel(\"R$^2$\",fontsize=14)\n",
    "                ax.set_ylim(-6,1)\n",
    "                ax.set_title(\"(c)\",fontsize=15)\n",
    "            elif jj == 3:\n",
    "                ax.set_ylabel(\"Maximum absolute error [W/m$^2$]\",fontsize=14)\n",
    "                ax.set_ylim(0.3,1.1)\n",
    "                ax.set_title(\"(d)\",fontsize=15)\n",
    "            elif jj == 4:\n",
    "                ax.set_ylabel(\"Mean Error (truth - prediction) [W/m$^2$]\",fontsize=14)\n",
    "                ax.set_ylim(-0.2,0.2)\n",
    "                ax.set_title(\"(e)\",fontsize=15)\n",
    "    \n",
    "\n",
    "# Get model settings\n",
    "settings = experiment_settings.get_settings(\"MPI_IV_hpt003\")\n",
    "\n",
    "# Load predictions\n",
    "settings[\"rng_seed\"] = 3\n",
    "model_name = file_methods.get_model_name(settings)\n",
    "predictions = file_methods.load_predictions(PREDICTIONS_DIRECTORY + model_name + \"_predictions.pickle\")\n",
    "\n",
    "label5, preds5, label95, preds95 = get_percentiles(predictions[\"labels_val\"], predictions[\"pred_val\"], th=percentile_th)\n",
    "\n",
    "ax = plt.subplot(2, 3, 6)\n",
    "ax.scatter(predictions[\"labels_val\"], predictions[\"pred_val\"],s=2,color='k',label=\"All validation members\")\n",
    "ax.scatter(label5, preds5,s=2,color='r',label=\"Below 5th percentile\")\n",
    "ax.scatter(label95, preds95,s=2,color='g',label=\"Above 95th percentile\")\n",
    "ax.plot([-1.5,1.5],[-1.5,1.5],'k--')\n",
    "ax.set_xlim(-1.3,1.3)\n",
    "ax.set_ylim(-1.3,1.3)\n",
    "ax.set_xlabel(\"Truth [W/m$^2$]\",fontsize=14)\n",
    "ax.set_ylabel(\"Prediction [W/m$^2$]\",fontsize=14)\n",
    "ax.set_title(\"(f)\",fontsize=15)\n",
    "ax.legend(fontsize=14,markerscale=3,frameon=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
